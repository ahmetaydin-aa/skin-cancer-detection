{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nfrom glob import glob\nimport seaborn as sns\nbase_skin_dir = os.path.join('..', 'input')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma', # dermatofibroma -> Melanoma olarak değiştirildi\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fe3fa263cf51fd0fbb29179bd00c3b936b79be0"},"cell_type":"code","source":"tile_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\ntile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\ntile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \ntile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\ntile_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"886afc98e3a49e6520108611a6b034b9aaac37dc"},"cell_type":"code","source":"tile_df.describe(exclude=[np.number])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a5694fdfd2d9898fbded5019cd126ef5b8387c2"},"cell_type":"code","source":"display(tile_df['cell_type'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8b50bd507bdf92d6bf6de0c907a76f22030b3f6"},"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize= (15, 7))\ntile_df['cell_type'].value_counts().plot(kind='bar', ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d265df47a682209cfd6d5bec9b95d9877484dca4"},"cell_type":"code","source":"from skimage.io import imread\nfrom tensorflow.image import rgb_to_grayscale\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nimage_size = 100\n\ndef read_and_prep_images(img_paths, img_width=image_size, img_height=image_size):\n    imgs = [np.asarray(Image.open(img_path).resize((img_height, img_width))) for img_path in img_paths]\n    img_arr = [preprocess_input(img) for img in imgs]\n    return img_arr\n\n#tile_df['image'] = tile_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100, 75))))\ntile_df['image'] = read_and_prep_images(tile_df['path'], 100, 75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2403048a683f3ac2343089cd540c6b1c04f2c825","scrolled":false},"cell_type":"code","source":"import tensorflow as tf\nimg = np.asarray(Image.open(tile_df[\"path\"][300]).resize((75, 100)))\nimg_g = preprocess_input(img)\nprint(img_g.shape)\nfig, ax = plt.subplots(1, 2, figsize=(20, 8))\nax[0].imshow(img)\nax[1].imshow(img_g, cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de1b2e37fb80db06af0a4a27f9cb959d452fe44c"},"cell_type":"code","source":"tile_df['image'].map(lambda x: x.shape).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c0f4ca96bd7ed2e60680d436e003f51193556af","scrolled":false},"cell_type":"code","source":"n_samples = 5\nfig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\nfor n_axs, (type_name, type_rows) in zip(m_axs, \n                                         tile_df.sort_values(['cell_type']).groupby('cell_type')):\n    n_axs[0].set_title(type_name)\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=2018).iterrows()):\n        c_ax.imshow(c_row['image'], cmap='gray')\n        c_ax.axis('off')\nfig.savefig('category_samples.png', dpi=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a54c05216d224567b2687d57c78aabcf9c1e67"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(tile_df['image'], tile_df['cell_type_idx'], test_size=0.2, random_state=42)\n#train_X, validation_X, train_y, validation_y = train_test_split(train_X, train_y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bf4fef0f409fcab466feed9478dbf7380194530"},"cell_type":"code","source":"train_X = np.asarray(train_X.tolist())\ntest_X = np.asarray(test_X.tolist())\n#validation_X = np.asarray(validation_X.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"533912a47e7bc7b9410705fae4c6c48fb1ad8a77"},"cell_type":"code","source":"def rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(train_X[0])\nax[1].imshow(rgb2gray(train_X[0]), cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a109fe3259200f1fab2379248d8a40e4cc75d94e"},"cell_type":"code","source":"x_train_mean = np.mean(train_X)\nx_train_std = np.std(train_X)\n\nx_test_mean = np.mean(test_X)\nx_test_std = np.std(test_X)\n\n#x_val_mean = np.mean(validation_X)\n#x_val_std = np.std(validation_X)\n\ntrain_X = (train_X - x_train_mean)/x_train_std\ntest_X = (test_X - x_test_mean)/x_test_std\n#validation_X = (validation_X - x_val_mean)/x_val_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1e148f83b942368c79310b0e511c4a253c581e7"},"cell_type":"code","source":"fig, ax = plt.subplots(1,2)\nax[0].imshow(train_X[0])\nax[1].imshow(rgb2gray(train_X[0]), cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f78fd73debe6dc49456fac70e224b54850e49e70"},"cell_type":"code","source":"#train_X = train_X.reshape(train_X.shape[0], *(75, 100, 3))\n#test_X = test_X.reshape(test_X.shape[0], *(75, 100, 3))\n#validation_X = validation_X.reshape(validation_X.shape[0], *(75, 100, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02b4bb43ec4a7c3553a828ba7ed8430e1131b155"},"cell_type":"code","source":"fig, ax = plt.subplots(1,2)\nax[0].imshow(train_X[0])\nax[1].imshow(rgb2gray(train_X[0]), cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c54e984954fa5b43adf5dcf4a4947a7ee0da33f"},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\ntrain_y = to_categorical(train_y, num_classes = 7)\ntest_y = to_categorical(test_y, num_classes = 7)\n#validation_y = to_categorical(validation_y, num_classes = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3db2fa6935bbef643ca6b5b23f98de9e87d8567"},"cell_type":"code","source":"import keras as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Lambda, Conv2D, MaxPool2D, Dropout, BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom IPython.display import clear_output\n\nclass PlotLosses(K.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.accs = []\n        self.val_accs = []\n        self.fig = plt.figure()\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.accs.append(logs.get('acc'))\n        self.val_accs.append(logs.get('val_acc'))\n        self.i += 1\n        \n        clear_output(wait=True)\n        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n        ax[0].plot(self.x, self.losses, label=\"loss\")\n        ax[0].plot(self.x, self.val_losses, label=\"val_loss\")\n        ax[0].legend()\n        ax[1].plot(self.x, self.accs, label=\"accuracy\")\n        ax[1].plot(self.x, self.val_accs, label=\"val_accuracy\")\n        ax[1].legend()\n        plt.legend()\n        plt.show();\n        \nplot_losses = PlotLosses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e53ba7f491fe7c486cea8b7379f2c0586aa49aa"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, precision_recall_curve, average_precision_score\nimport itertools\n\ndef plot_confusion_matrix(ax, cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    fmt = '.2f'\n    tick_marks = np.arange(len(classes))\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_title(title)\n    ax.set_xticks(tick_marks)\n    ax.set_xticklabels(classes)\n    ax.set_yticks(tick_marks)\n    ax.set_yticklabels(classes, rotation=90, va=\"center\")\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        ax.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    ax.set_ylabel('True label')\n    ax.set_xlabel('Predicted label')\n    \ndef plot_roc_curve(ax, y, y_pred, title=\"ROC Curve\"):\n    fpr, tpr, thresholds_roc = roc_curve(y, y_pred)\n    roc_auc = auc(fpr,tpr)\n    ax.plot(fpr,tpr, label = \"AUC = {:0.2f}\".format(roc_auc), lw = 3, alpha = 0.7)\n    ax.plot([0,1], [0,1], 'r', linestyle = \"--\", lw = 2)\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive Rate\")\n    ax.set_title(title)\n    ax.legend(loc = 'best')\n    close_default = np.argmin(np.abs(thresholds_roc - 0.5))\n    ax.plot(fpr[close_default], tpr[close_default], 'o', markersize = 8)\n\ndef plot_presicion_recall_curve(ax, y, y_pred_proba, title=\"Precision-Recall Curve\"):\n    precision, recall, thresholds_pr = precision_recall_curve(y, y_pred_proba)\n    avg_pre = average_precision_score(y, y_pred_proba)\n    area = auc(recall, precision)\n    ax.plot(recall, precision, label = \"Average precision = {:0.2f}, AUC = {:0.2f}\".format(avg_pre, area), lw = 3, alpha = 0.7)\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    ax.set_title(title)\n    ax.legend(loc = 'best')\n    # plot no skill\n    ax.plot([0, 1], [0.5, 0.5], linestyle='--')\n    #find default threshold\n    close_default = np.argmin(np.abs(thresholds_pr - 0.5))\n    ax.plot(precision[close_default], recall[close_default], 'o', markersize = 8)\n    \ndef bilgileri_cikar(model, model_title):\n    test_pred = model.predict_classes(test_X)\n    test_pred_proba = model.predict_proba(test_X)[:,1]\n    \n    train_score = model.evaluate(train_X, train_y)[1]\n    test_score = model.evaluate(test_X, test_y)[1]\n    \n    classes = list(range(7))\n    classes = pd.Categorical.from_codes(classes, sorted(lesion_type_dict.values()))\n    classes = np.array(classes)\n    sinir = \"\\n\" + \"-\"*50\n    \n    print(\"=\"*6, \"Skorlar\", \"=\"*6)\n    print(\"Training Score:\\t{:.4f}\".format(train_score))\n    print(\"Test Score:\\t\\t{:.4f}\".format(test_score))\n    np.set_printoptions(precision=2)\n    \n    print(sinir)\n    print(\"=\"*6, \"Test Sınıflandırma Raporu\", \"=\"*6)\n    test_y_uc = pd.DataFrame([np.argmax(y) for y in test_y])\n    print(classification_report(test_y_uc, test_pred))\n    cnf_matrix1 = confusion_matrix(test_y_uc, test_pred)\n    cnf_matrix1_nrm = cnf_matrix1.astype('float') / cnf_matrix1.sum(axis=1)[:, np.newaxis]\n    print(sinir)\n    \n    fig, ax = plt.subplots(1, figsize=(17, 17)) \n    fig.suptitle(model_title, fontsize=20)\n    plot_confusion_matrix(ax, cnf_matrix1_nrm, classes, title='Test Confusion Matrix')\n    #plot_roc_curve(ax[0,1], test_y_uc, test_pred_proba, title=\"Test ROC Curve\")\n    #plot_presicion_recall_curve(ax[0,2], test_y_uc, test_pred_proba, title=\"Test Precision-Recall Curve\")\n\ndef precision_hesapla(TP, FP):\n    return TP/(TP + FP)\n\ndef recall_hesapla(TP, FN):\n    return TP/(TP + FN)\n    \ndef ortalama(x):\n    return (x[1]+x[2])/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4871eef5abdd3f737bd5314caccebaf2a8f806ba"},"cell_type":"code","source":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nbatch_size = 32\n\ngenerator = ImageDataGenerator(\n    validation_split=0.1,\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=20,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=False,\n    vertical_flip=False)\n\ngenerator.fit(train_X)\n\ntrain_generator = generator.flow(\n    train_X,\n    train_y,\n    batch_size=batch_size,\n    subset='training') # set as training data\n\nvalidation_generator = generator.flow(\n    train_X,\n    train_y,\n    batch_size=batch_size,\n    subset='validation') # set as training data\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89bc5ec7efd7623872cc62def5ac4b13f8be7b7e"},"cell_type":"code","source":"K.backend.clear_session()\ninput_shape = (100, 75, 3)\nnum_classes = 7\n\nmodel = Sequential()\n#model.add(Lambda(lambda x: rgb_to_grayscale(x), input_shape = input_shape))\nmodel.add(Conv2D(128, kernel_size=(3, 3), input_shape = input_shape))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(Conv2D(128, kernel_size=(3, 3)))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(MaxPool2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization(momentum=0.3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(BatchNormalization(momentum=0.2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.3))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d848fa4783b161be6640ae361a129007cad23961"},"cell_type":"code","source":"model.compile(optimizer=K.optimizers.Adam() , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a3f378471aa2d8526510a86888aaf7215b50230"},"cell_type":"code","source":"model.fit_generator(generator=train_generator, steps_per_epoch = len(train_X)//batch_size,\n                    validation_data=validation_generator, validation_steps = (len(train_X)*0.1)//batch_size,\n                    epochs=50, callbacks=[learning_rate_reduction, plot_losses])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a881595ecb55bb410ff8ef96c863483d1d3f8a3"},"cell_type":"code","source":"bilgileri_cikar(model, \"CNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9946c7d3767a6a0904034eec686f14bd364ae39"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}